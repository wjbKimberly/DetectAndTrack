{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'frame_id': 1, 'width': 1280, 'nframes': 149, 'is_labeled': True, 'height': 720, 'original_file_name': 'images/bonn_5sec/015860_mpii/00000001.jpg', 'id': 1, 'file_name': 'bonn_5sec/015860_mpii/00000001.jpg'}, {'frame_id': 2, 'width': 1280, 'nframes': 149, 'is_labeled': False, 'height': 720, 'original_file_name': 'images/bonn_5sec/015860_mpii/00000002.jpg', 'id': 2, 'file_name': 'bonn_5sec/015860_mpii/00000002.jpg'}, {'frame_id': 3, 'width': 1280, 'nframes': 149, 'is_labeled': False, 'height': 720, 'original_file_name': 'images/bonn_5sec/015860_mpii/00000003.jpg', 'id': 3, 'file_name': 'bonn_5sec/015860_mpii/00000003.jpg'}, {'frame_id': 4, 'width': 1280, 'nframes': 149, 'is_labeled': False, 'height': 720, 'original_file_name': 'images/bonn_5sec/015860_mpii/00000004.jpg', 'id': 4, 'file_name': 'bonn_5sec/015860_mpii/00000004.jpg'}, {'frame_id': 5, 'width': 1280, 'nframes': 149, 'is_labeled': True, 'height': 720, 'original_file_name': 'images/bonn_5sec/015860_mpii/00000005.jpg', 'id': 5, 'file_name': 'bonn_5sec/015860_mpii/00000005.jpg'}, {'frame_id': 6, 'width': 1280, 'nframes': 149, 'is_labeled': False, 'height': 720, 'original_file_name': 'images/bonn_5sec/015860_mpii/00000006.jpg', 'id': 6, 'file_name': 'bonn_5sec/015860_mpii/00000006.jpg'}, {'frame_id': 7, 'width': 1280, 'nframes': 149, 'is_labeled': False, 'height': 720, 'original_file_name': 'images/bonn_5sec/015860_mpii/00000007.jpg', 'id': 7, 'file_name': 'bonn_5sec/015860_mpii/00000007.jpg'}, {'frame_id': 8, 'width': 1280, 'nframes': 149, 'is_labeled': False, 'height': 720, 'original_file_name': 'images/bonn_5sec/015860_mpii/00000008.jpg', 'id': 8, 'file_name': 'bonn_5sec/015860_mpii/00000008.jpg'}, {'frame_id': 9, 'width': 1280, 'nframes': 149, 'is_labeled': True, 'height': 720, 'original_file_name': 'images/bonn_5sec/015860_mpii/00000009.jpg', 'id': 9, 'file_name': 'bonn_5sec/015860_mpii/00000009.jpg'}, {'frame_id': 10, 'width': 1280, 'nframes': 149, 'is_labeled': False, 'height': 720, 'original_file_name': 'images/bonn_5sec/015860_mpii/00000010.jpg', 'id': 10, 'file_name': 'bonn_5sec/015860_mpii/00000010.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Copyright (c) 2018-present, Facebook, Inc.\n",
    "# All rights reserved.\n",
    "#\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "##############################################################\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import json\n",
    "import os\n",
    "import os.path as osp\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from convert.loader import load_mat\n",
    "from convert.box import compute_boxes_from_pose\n",
    "from utils.general import mkdir_p\n",
    "from convert.data import get_posetrack_kpt_ordering\n",
    "\n",
    "# Directory with annotation mat files downloaded from PoseTrack website\n",
    "\n",
    "\n",
    "mat_dir = '/home/data/posetrack_data/posetrack_data/annotations/{}'\n",
    "out_path = '/home/data/posetrack_data/posetrack_data_json/posetrack_{}_small.json'\n",
    "\n",
    "# mat_dir = '/path/to/posetrack_data/annotations/{}'\n",
    "# out_path = '/path/to/output/jsons/posetrack_{}.json'\n",
    "splits = ['val_small']\n",
    "# splits = ['test', 'train', 'val']\n",
    "# Set this to true if need to re-create the video frames. Note that the\n",
    "# original frames are in non-standard file format so will need to be fixed.\n",
    "if 1:  # `convert` the frames to standard format\n",
    "    recreate_videos = True\n",
    "    vid_indir = '/home/data/posetrack_data/posetrack_data/images'\n",
    "    vid_outdir = '/home/data/posetrack_data/posetrack_data/converted_images'\n",
    "#     vid_indir = '/path/to/posetrack_data/images'\n",
    "#     vid_outdir = '/path/to/output/images_renamed'\n",
    "else:  # `convert`-ed frames already exist, do not redo\n",
    "    recreate_videos = False\n",
    "    vid_indir = ''\n",
    "    vid_outdir = '/path/to/output/images_renamed'\n",
    "\n",
    "\n",
    "def _get_video_info(vpath):\n",
    "    frame_ids = sorted([int(osp.basename(\n",
    "        el).split('.')[0]) for el in os.listdir(vpath)])\n",
    "    nframes = len(frame_ids)\n",
    "    assert(frame_ids[0] == 1)\n",
    "    assert(frame_ids[-1] == nframes)\n",
    "    frame1 = osp.join(vpath, '00000001.jpg')\n",
    "    wd, ht = Image.open(frame1).size\n",
    "    return {'nframes': nframes, 'width': wd, 'height': ht}\n",
    "\n",
    "\n",
    "def _convert_video_frame_ids(inpath, outpath):\n",
    "    \"\"\"\n",
    "    PoseTrack videos follow no consistent naming for frames. Make it consistent\n",
    "    \"\"\"\n",
    "    mkdir_p(outpath)\n",
    "    frame_names = [osp.basename(el) for el in glob.glob(osp.join(\n",
    "        inpath, '*.jpg'))]\n",
    "    # Some videos have 00XX_crop.jpg style filenames\n",
    "    frame_ids = [int(el.split('.')[0].split('_')[0]) for el in frame_names]\n",
    "    id_to_name = dict(zip(frame_ids, frame_names))\n",
    "    for i, fid in enumerate(sorted(frame_ids)):\n",
    "        shutil.copy('{}/{}'.format(inpath, id_to_name[fid]),\n",
    "                    '{}/{:08d}.jpg'.format(outpath, i + 1))\n",
    "\n",
    "\n",
    "def _load_mat_files(annot_dir):\n",
    "    mat_data = {}\n",
    "    print('Loading data from MAT files...')\n",
    "    for fpath in tqdm(glob.glob(osp.join(annot_dir, '*.mat'))):\n",
    "        stuff = load_mat(fpath)\n",
    "        if len(stuff) > 0:\n",
    "            key = osp.dirname(stuff[0].im_name)\n",
    "            key = key[len('images/'):]\n",
    "            mat_data[key] = stuff\n",
    "    return mat_data\n",
    "\n",
    "\n",
    "def _get_person_category_data():\n",
    "    category = {\n",
    "        \"supercategory\": \"person\",\n",
    "        \"id\": 1,  # to be same as COCO, not using 0\n",
    "        \"name\": \"person\",\n",
    "        \"skeleton\": [[16, 14],\n",
    "                     [14, 12],\n",
    "                     [17, 15],\n",
    "                     [15, 13],\n",
    "                     [12, 13],\n",
    "                     [6, 12],\n",
    "                     [7, 13],\n",
    "                     [6, 7],\n",
    "                     [6, 8],\n",
    "                     [7, 9],\n",
    "                     [8, 10],\n",
    "                     [9, 11],\n",
    "                     [2, 3],\n",
    "                     [1, 2],\n",
    "                     [1, 3],\n",
    "                     [2, 4],\n",
    "                     [3, 5],\n",
    "                     [4, 6],\n",
    "                     [5, 7]],\n",
    "        \"keypoints\": [\"nose\",\n",
    "                      \"head_bottom\",  # \"left_eye\",\n",
    "                      \"head_top\",  # \"right_eye\",\n",
    "                      \"left_ear\",\n",
    "                      \"right_ear\", \"left_shoulder\", \"right_shoulder\",\n",
    "                      \"left_elbow\", \"right_elbow\", \"left_wrist\",\n",
    "                      \"right_wrist\", \"left_hip\", \"right_hip\", \"left_knee\",\n",
    "                      \"right_knee\", \"left_ankle\", \"right_ankle\"]}\n",
    "    return category\n",
    "\n",
    "\n",
    "def _get_categories_data():\n",
    "    return [_get_person_category_data()]\n",
    "\n",
    "\n",
    "def _gen_image_structure(vname, frame_id, frame_data, vid_info, imid):\n",
    "    image = {}\n",
    "    # ordering in data based on tools/video/extract_metadata.py\n",
    "    image['nframes'] = int(vid_info['nframes'])\n",
    "    image['frame_id'] = int(frame_id)\n",
    "    image['width'] = int(vid_info['width'])\n",
    "    image['height'] = int(vid_info['height'])\n",
    "    # frames-in-dir kinda videos. The {:08d}.jpg is how I rename it\n",
    "    image['file_name'] = osp.join(vname, '{:08d}.jpg'.format(frame_id))\n",
    "    image['original_file_name'] = frame_data.im_name\n",
    "    image['is_labeled'] = frame_data.is_labeled\n",
    "    image['id'] = imid\n",
    "    return image\n",
    "\n",
    "\n",
    "def _get_posetrack_to_coco_permut():\n",
    "    print('Computing permutation from posetrack to COCO.')\n",
    "    target_ordering = _get_person_category_data()['keypoints']\n",
    "    given_ordering, _ = get_posetrack_kpt_ordering()\n",
    "    permut_ordering = []\n",
    "    for given_kpt_id, given_kpt in enumerate(given_ordering):\n",
    "        new_id = target_ordering.index(given_kpt)\n",
    "        # Make sure all points get assigned somewhere.\n",
    "        # COCO has 17 kpts, so the other kpts in posetrack can replace the ones\n",
    "        # we don't have labels for in posetrack (eye/ear)\n",
    "        assert(new_id > -1)\n",
    "        print('{} -> {}'.format(given_kpt_id, new_id))\n",
    "        permut_ordering.append(new_id)\n",
    "    return permut_ordering\n",
    "\n",
    "\n",
    "def _convert_posetrack_kps_to_coco(posetrack_pose, permut_ordering):\n",
    "    res = np.zeros(\n",
    "        (len(_get_person_category_data()['keypoints']), 3),\n",
    "        dtype=posetrack_pose.dtype)\n",
    "    res[np.array(permut_ordering), :] = posetrack_pose\n",
    "    return res\n",
    "\n",
    "\n",
    "def _gen_annot_structure(box_data, kpt_permut_ordering, imid, annid):\n",
    "    ann = {}\n",
    "    ann['id'] = annid\n",
    "    ann['image_id'] = imid\n",
    "    ann['iscrowd'] = 0\n",
    "    ann['segmentation'] = []\n",
    "    ann['num_keypoints'] = 17  # COCO\n",
    "    ann['category_id'] = 1  # person\n",
    "    ann['track_id'] = box_data.track_id\n",
    "    ann['head_box'] = [float(el) for el in box_data.head]\n",
    "    ann['keypoints'] = _convert_posetrack_kps_to_coco(\n",
    "        box_data.pose, kpt_permut_ordering).reshape((-1)).tolist()\n",
    "    ann['bbox'] = compute_boxes_from_pose([[ann['keypoints']]])[0][0]\n",
    "    ann['area'] = ann['bbox'][-1] * ann['bbox'][-2]\n",
    "    return ann\n",
    "\n",
    "\n",
    "def _convert_mat_to_COCO_json(\n",
    "        annot_dir, out_path, vid_indir, vid_outdir, recreate_videos,\n",
    "        permut_ordering):\n",
    "    # Generate the output structure\n",
    "    res = {}\n",
    "    res['images'] = []\n",
    "    res['annotations'] = []\n",
    "    res['categories'] = _get_categories_data()\n",
    "\n",
    "    # load all the mat files\n",
    "    all_annots = _load_mat_files(annot_dir)\n",
    "    print('Processing MAT files into JSON structures...')\n",
    "    for vid_name in tqdm(all_annots.keys()):\n",
    "        # Convert the posetrack video into a sane format\n",
    "        if recreate_videos:\n",
    "            assert(len(vid_indir) > 0)\n",
    "            _convert_video_frame_ids(\n",
    "                osp.join(vid_indir, vid_name),\n",
    "                osp.join(vid_outdir, vid_name))\n",
    "        vid_info = _get_video_info(osp.join(vid_outdir, vid_name))\n",
    "        vid_data = all_annots[vid_name]\n",
    "        nframes = len(vid_data)\n",
    "        for frame_id in range(1, nframes + 1):\n",
    "            frame_data = vid_data[frame_id - 1]\n",
    "            image_struct = _gen_image_structure(\n",
    "                vid_name, frame_id, frame_data, vid_info,\n",
    "                len(res['images']) + 1)\n",
    "            res['images'].append(image_struct)\n",
    "            if frame_data.is_labeled:\n",
    "                for box_data in frame_data.boxes:\n",
    "                    annot_struct = _gen_annot_structure(\n",
    "                        box_data,\n",
    "                        permut_ordering,\n",
    "                        imid=len(res['images']),\n",
    "                        annid=len(res['annotations']) + 1)\n",
    "                    res['annotations'].append(annot_struct)\n",
    "    with open(out_path, 'w') as fout:\n",
    "        json.dump(res, fout)\n",
    "\n",
    "\n",
    "def main():\n",
    "    permut_ordering = _get_posetrack_to_coco_permut()\n",
    "    for split in splits:\n",
    "        print('Processing {} split'.format(split))\n",
    "        _convert_mat_to_COCO_json(\n",
    "            mat_dir.format(split), out_path.format(split),\n",
    "            vid_indir, vid_outdir, recreate_videos, permut_ordering)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
