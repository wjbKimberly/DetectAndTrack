{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:00<00:00,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing permutation from posetrack to COCO.\n",
      "0 -> 16\n",
      "1 -> 14\n",
      "2 -> 12\n",
      "3 -> 11\n",
      "4 -> 13\n",
      "5 -> 15\n",
      "6 -> 10\n",
      "7 -> 8\n",
      "8 -> 6\n",
      "9 -> 5\n",
      "10 -> 7\n",
      "11 -> 9\n",
      "12 -> 1\n",
      "13 -> 0\n",
      "14 -> 2\n",
      "Processing val_small split\n",
      "Loading data from MAT files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 12.74it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MAT files into JSON structures...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:38<00:00,  7.65s/it]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# Copyright (c) 2018-present, Facebook, Inc.\n",
    "# All rights reserved.\n",
    "#\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "##############################################################\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import json\n",
    "import os\n",
    "import os.path as osp\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '../lib/'))\n",
    "\n",
    "from convert.loader import load_mat\n",
    "from convert.box import compute_boxes_from_pose\n",
    "from utils.general import mkdir_p\n",
    "from convert.data import get_posetrack_kpt_ordering\n",
    "\n",
    "# Directory with annotation mat files downloaded from PoseTrack website\n",
    "\n",
    "\n",
    "mat_dir = '../../DetectAndTrack-wjb/lib/datasets/data/PoseTrackV1.0_Annots_val_small_json/'\n",
    "out_path = '../../DetectAndTrack-wjb/lib/datasets/lists/PoseTrack/v1.0/posetrack_{}.json'\n",
    "\n",
    "# mat_dir = '/path/to/posetrack_data/annotations/{}'\n",
    "# out_path = '/path/to/output/jsons/posetrack_{}.json'\n",
    "splits = ['val_small']\n",
    "# splits = ['test', 'train', 'val']\n",
    "# Set this to true if need to re-create the video frames. Note that the\n",
    "# original frames are in non-standard file format so will need to be fixed.\n",
    "if 1:  # `convert` the frames to standard format\n",
    "    recreate_videos = True\n",
    "    vid_indir = '../../DetectAndTrack-wjb/lib/datasets/data/PoseTrack/posetrack_data/images'\n",
    "    vid_outdir = '../../DetectAndTrack-wjb/lib/datasets/data/PoseTrack/posetrack_data/converted_images'\n",
    "#     vid_indir = '/path/to/posetrack_data/images'\n",
    "#     vid_outdir = '/path/to/output/images_renamed'\n",
    "else:  # `convert`-ed frames already exist, do not redo\n",
    "    recreate_videos = False\n",
    "    vid_indir = ''\n",
    "    vid_outdir = '/path/to/output/images_renamed'\n",
    "\n",
    "\n",
    "def _get_video_info(vpath):\n",
    "    frame_ids = sorted([int(osp.basename(\n",
    "        el).split('.')[0]) for el in os.listdir(vpath)])\n",
    "    nframes = len(frame_ids)\n",
    "    assert(frame_ids[0] == 1)\n",
    "    assert(frame_ids[-1] == nframes)\n",
    "    frame1 = osp.join(vpath, '00000001.jpg')\n",
    "    wd, ht = Image.open(frame1).size\n",
    "    return {'nframes': nframes, 'width': wd, 'height': ht}\n",
    "\n",
    "\n",
    "def _convert_video_frame_ids(inpath, outpath):\n",
    "    \"\"\"\n",
    "    PoseTrack videos follow no consistent naming for frames. Make it consistent\n",
    "    \"\"\"\n",
    "    mkdir_p(outpath)\n",
    "    frame_names = [osp.basename(el) for el in glob.glob(osp.join(\n",
    "        inpath, '*.jpg'))]\n",
    "    # Some videos have 00XX_crop.jpg style filenames\n",
    "    frame_ids = [int(el.split('.')[0].split('_')[0]) for el in frame_names]\n",
    "    id_to_name = dict(zip(frame_ids, frame_names))\n",
    "    for i, fid in enumerate(sorted(frame_ids)):\n",
    "        shutil.copy('{}/{}'.format(inpath, id_to_name[fid]),\n",
    "                    '{}/{:08d}.jpg'.format(outpath, i + 1))\n",
    "\n",
    "\n",
    "def _load_mat_files(annot_dir):\n",
    "    mat_data = {}\n",
    "    print('Loading data from MAT files...')\n",
    "    for fpath in tqdm(glob.glob(osp.join(annot_dir, '*.mat'))):\n",
    "        stuff = load_mat(fpath)\n",
    "        if len(stuff) > 0:\n",
    "            key = osp.dirname(stuff[0].im_name)\n",
    "            key = key[len('images/'):]\n",
    "            mat_data[key] = stuff\n",
    "    return mat_data\n",
    "\n",
    "\n",
    "def _get_person_category_data():\n",
    "    category = {\n",
    "        \"supercategory\": \"person\",\n",
    "        \"id\": 1,  # to be same as COCO, not using 0\n",
    "        \"name\": \"person\",\n",
    "        \"skeleton\": [[16, 14],\n",
    "                     [14, 12],\n",
    "                     [17, 15],\n",
    "                     [15, 13],\n",
    "                     [12, 13],\n",
    "                     [6, 12],\n",
    "                     [7, 13],\n",
    "                     [6, 7],\n",
    "                     [6, 8],\n",
    "                     [7, 9],\n",
    "                     [8, 10],\n",
    "                     [9, 11],\n",
    "                     [2, 3],\n",
    "                     [1, 2],\n",
    "                     [1, 3],\n",
    "                     [2, 4],\n",
    "                     [3, 5],\n",
    "                     [4, 6],\n",
    "                     [5, 7]],\n",
    "        \"keypoints\": [\"nose\",\n",
    "                      \"head_bottom\",  # \"left_eye\",\n",
    "                      \"head_top\",  # \"right_eye\",\n",
    "                      \"left_ear\",\n",
    "                      \"right_ear\", \"left_shoulder\", \"right_shoulder\",\n",
    "                      \"left_elbow\", \"right_elbow\", \"left_wrist\",\n",
    "                      \"right_wrist\", \"left_hip\", \"right_hip\", \"left_knee\",\n",
    "                      \"right_knee\", \"left_ankle\", \"right_ankle\"]}\n",
    "    return category\n",
    "\n",
    "\n",
    "def _get_categories_data():\n",
    "    return [_get_person_category_data()]\n",
    "\n",
    "\n",
    "def _gen_image_structure(vname, frame_id, frame_data, vid_info, imid):\n",
    "    image = {}\n",
    "    # ordering in data based on tools/video/extract_metadata.py\n",
    "    image['nframes'] = int(vid_info['nframes'])\n",
    "    image['frame_id'] = int(frame_id)\n",
    "    image['width'] = int(vid_info['width'])\n",
    "    image['height'] = int(vid_info['height'])\n",
    "    # frames-in-dir kinda videos. The {:08d}.jpg is how I rename it\n",
    "    image['file_name'] = osp.join(vname, '{:08d}.jpg'.format(frame_id))\n",
    "    image['original_file_name'] = frame_data.im_name\n",
    "    image['is_labeled'] = frame_data.is_labeled\n",
    "    image['id'] = imid\n",
    "    return image\n",
    "\n",
    "\n",
    "def _get_posetrack_to_coco_permut():\n",
    "    print('Computing permutation from posetrack to COCO.')\n",
    "    target_ordering = _get_person_category_data()['keypoints']\n",
    "    given_ordering, _ = get_posetrack_kpt_ordering()\n",
    "    permut_ordering = []\n",
    "    for given_kpt_id, given_kpt in enumerate(given_ordering):\n",
    "        new_id = target_ordering.index(given_kpt)\n",
    "        # Make sure all points get assigned somewhere.\n",
    "        # COCO has 17 kpts, so the other kpts in posetrack can replace the ones\n",
    "        # we don't have labels for in posetrack (eye/ear)\n",
    "        assert(new_id > -1)\n",
    "        print('{} -> {}'.format(given_kpt_id, new_id))\n",
    "        permut_ordering.append(new_id)\n",
    "    return permut_ordering\n",
    "\n",
    "\n",
    "def _convert_posetrack_kps_to_coco(posetrack_pose, permut_ordering):\n",
    "    res = np.zeros(\n",
    "        (len(_get_person_category_data()['keypoints']), 3),\n",
    "        dtype=posetrack_pose.dtype)\n",
    "    res[np.array(permut_ordering), :] = posetrack_pose\n",
    "    return res\n",
    "\n",
    "\n",
    "def _gen_annot_structure(box_data, kpt_permut_ordering, imid, annid):\n",
    "    ann = {}\n",
    "    ann['id'] = annid\n",
    "    ann['image_id'] = imid\n",
    "    ann['iscrowd'] = 0\n",
    "    ann['segmentation'] = []\n",
    "    ann['num_keypoints'] = 17  # COCO\n",
    "    ann['category_id'] = 1  # person\n",
    "    ann['track_id'] = box_data.track_id\n",
    "    ann['head_box'] = [float(el) for el in box_data.head]\n",
    "    ann['keypoints'] = _convert_posetrack_kps_to_coco(\n",
    "        box_data.pose, kpt_permut_ordering).reshape((-1)).tolist()\n",
    "    ann['bbox'] = compute_boxes_from_pose([[ann['keypoints']]])[0][0]\n",
    "    ann['area'] = ann['bbox'][-1] * ann['bbox'][-2]\n",
    "    return ann\n",
    "\n",
    "\n",
    "def _convert_mat_to_COCO_json(\n",
    "        annot_dir, out_path, vid_indir, vid_outdir, recreate_videos,\n",
    "        permut_ordering):\n",
    "    # Generate the output structure\n",
    "    res = {}\n",
    "    res['images'] = []\n",
    "    res['annotations'] = []\n",
    "    res['categories'] = _get_categories_data()\n",
    "\n",
    "    # load all the mat files\n",
    "    all_annots = _load_mat_files(annot_dir)\n",
    "    print('Processing MAT files into JSON structures...')\n",
    "    for vid_name in tqdm(all_annots.keys()):\n",
    "        # Convert the posetrack video into a sane format\n",
    "        if recreate_videos:\n",
    "            assert(len(vid_indir) > 0)\n",
    "            _convert_video_frame_ids(\n",
    "                osp.join(vid_indir, vid_name),\n",
    "                osp.join(vid_outdir, vid_name))\n",
    "        vid_info = _get_video_info(osp.join(vid_outdir, vid_name))\n",
    "        vid_data = all_annots[vid_name]\n",
    "        nframes = len(vid_data)\n",
    "        for frame_id in range(1, nframes + 1):\n",
    "            frame_data = vid_data[frame_id - 1]\n",
    "            image_struct = _gen_image_structure(\n",
    "                vid_name, frame_id, frame_data, vid_info,\n",
    "                len(res['images']) + 1)\n",
    "            res['images'].append(image_struct)\n",
    "            if frame_data.is_labeled:\n",
    "                for box_data in frame_data.boxes:\n",
    "                    annot_struct = _gen_annot_structure(\n",
    "                        box_data,\n",
    "                        permut_ordering,\n",
    "                        imid=len(res['images']),\n",
    "                        annid=len(res['annotations']) + 1)\n",
    "                    res['annotations'].append(annot_struct)\n",
    "    with open(out_path, 'w') as fout:\n",
    "        json.dump(res, fout,indent=\"\\t\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    permut_ordering = _get_posetrack_to_coco_permut()\n",
    "    for split in splits:\n",
    "        print('Processing {} split'.format(split))\n",
    "        _convert_mat_to_COCO_json(\n",
    "            mat_dir.format(split), out_path.format(split),\n",
    "            vid_indir, vid_outdir, recreate_videos, permut_ordering)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
